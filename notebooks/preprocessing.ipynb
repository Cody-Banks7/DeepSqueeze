{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Specific Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor\n",
    "\n",
    "[Monitor benchmark dataset](https://github.com/crottyan/mgbench) is used for benchmarking mostly database engines MySQL index creation. As a result the dataset is huge (~7GB) exceeding my hardware limits.\n",
    "\n",
    "* Total remaining rows: 2,202,375\n",
    "* Columns: 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = pd.read_csv('../storage/datasets/monitor_bench1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only 10% of the rows\n",
    "monitor = monitor.iloc[:int(monitor.shape[0]*0.1), :]\n",
    "\n",
    "# Drop the categorical columns\n",
    "monitor = monitor.drop(['log_time', 'machine_name', 'machine_group'], axis=1)\n",
    "\n",
    "# Drop remaining NaN rows\n",
    "monitor = monitor.dropna()\n",
    "\n",
    "# Make sure that we keep only numerical (float) types\n",
    "print(monitor.dtypes)\n",
    "\n",
    "# Store it without the default pandas index and without the column names\n",
    "monitor.to_csv('../storage/datasets/monitor_preprocessed_0_1_fraction.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Berkeley\n",
    "\n",
    "[Berkeley](https://www.kaggle.com/divyansh22/intel-berkeley-research-lab-sensor-data) contains data from 51 environmentanl sensors in the Berkeley Research lab between February 28th and April 5th, 2004.\n",
    "\n",
    "* Total rows: 2,219,803\n",
    "* Columns: 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley = pd.read_csv('../storage/datasets/berkeley.csv', sep=' ', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find NaNs and drop them (~4% of the dataset)\n",
    "berkeley = berkeley.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform date column from yyyy-mm-dd to days from the start of the measurements (28/2/2014)\n",
    "year_dates = pd.to_datetime(berkeley.iloc[:, 0], format='%Y/%m/%d')\n",
    "basedate = pd.Timestamp('2004-2-28')\n",
    "days_elapsed = year_dates.apply(lambda x: (x - basedate).days)\n",
    "berkeley[0] = days_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform hour column from hh-mm-ss to days from the start of the measurements (28/2/2014)\n",
    "hour = pd.to_datetime(berkeley.iloc[:, 1])\n",
    "minutes_elapsed = ((hour - hour.dt.normalize()) / pd.Timedelta('1 minute')).astype(int)\n",
    "berkeley[1] = minutes_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store it without the default pandas index and without the column names\n",
    "berkeley.to_csv('../storage/datasets/berkeley_processed.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corel\n",
    "\n",
    "[Corel histogram dataset](https://kdd.ics.uci.edu/databases/CorelFeatures/CorelFeatures.data.html) consists of histogram color values of 68,040 photo images from various categories.\n",
    "\n",
    "\n",
    "* Total rows: 68,040\n",
    "* Columns: 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "corel = pd.read_csv('../storage/datasets/corel.csv', sep=' ', header=None, index_col=0)\n",
    "\n",
    "# Corel does not require any dataset-specific preprocessing, we just remove its index when we store it\n",
    "corel.to_csv('../storage/datasets/corel_preprocessed.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepSqueeze Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepSqueeze preprocessing consists of two steps:\n",
    "1. Scaling in range [0, 1]\n",
    "2. Quantization based on a user-defined threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_preprocessing(x, error_threshold, min_val=0, max_val=1):\n",
    "    # Scale in range [min_val, max_val]\n",
    "    scaler = MinMaxScaler((min_val, max_val))\n",
    "    processed = scaler.fit_transform(x)\n",
    "    \n",
    "    # Quantization\n",
    "    bins = np.arange(min_val, max_val, 2*error_threshold)\n",
    "    digitized = np.digitize(processed, bins)\n",
    "    quantized = (digitized-1) * (2*error_threshold) + error_threshold\n",
    "    \n",
    "    return quantized\n",
    "\n",
    "data_path = '../storage/datasets/monitor_0_1_fraction.csv'\n",
    "arr = np.array(pd.read_csv(data_path, header=None))\n",
    "proc = ds_preprocessing(arr, error_threshold=0.1, min_val=0, max_val=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
